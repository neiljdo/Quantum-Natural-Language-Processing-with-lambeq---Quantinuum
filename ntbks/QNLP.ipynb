{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62aeddb-431d-4da5-a604-cfa78b629d36",
   "metadata": {},
   "source": [
    "# Quantum NLP Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8384c50-e218-4748-8d3f-9d6a18f7c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad7c72-73bb-4bac-b1f2-5575e4994cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ca4c9-759f-4aa7-b62b-55e3d768fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e348b11-5fad-402e-b8ab-a7bc353650e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install pandas\n",
    "# !{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09019c59-286b-4983-8bdc-5a40c37191ab",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c0217-fdc7-4a66-aeac-23d8f5676d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import LovelyPlots.utils as lp\n",
    "lp.set_retina()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b0423-d07a-45e6-9e9e-91f7c4570b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "RANDOM_SEED = 220811\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015dfc8-fa54-47a8-a099-7ccba346c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c0b0f1-b807-422c-abb1-30a228b01814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import BobcatParser, DepCCGParser\n",
    "from discopy import grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85818514-b7e7-47e9-b85c-7bf2783375a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import Rewriter\n",
    "from lambeq import AtomicType, IQPAnsatz, remove_cups\n",
    "from lambeq import TketModel, NumpyModel\n",
    "from lambeq import QuantumTrainer, SPSAOptimizer\n",
    "from lambeq import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c3f270-2292-496a-aa29-ba4ba9077b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytket.circuit.display import render_circuit_jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0cfc9-f775-4d44-9b55-4588ad216deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytket.extensions.qiskit import AerBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9852ae6-ae20-448d-ad7d-653848b62db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from discopy.tensor import Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1440d9e-f9fd-4a49-b330-dfc552b3f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"MC1.TXT\", header=None, sep=\", \", engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c15c0-982e-430f-a385-8cafdb0e6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"s1\", \"s2\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d336df5e-0d38-493f-968d-1eeb99d3a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20daaeac-1e03-44ba-8024-edd3ac2ffc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "lengths = set()\n",
    "\n",
    "for i, r in df.iterrows():\n",
    "    tokens = r.s1.split(\" \")\n",
    "    lengths.add(len(tokens))\n",
    "    [vocab.add(w) for w in tokens]\n",
    "    tokens = r.s2.split(\" \")\n",
    "    lengths.add(len(tokens))\n",
    "    [vocab.add(w) for w in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9b3f5-9f3f-463d-a4e6-c62b40c8f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vocab, len(vocab), max(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dad7c-023c-4639-96ea-2fbbede0ee75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lambeq tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f6626b-fc30-4e2c-b798-f53068782e12",
   "metadata": {},
   "source": [
    "### Sentence input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b1054-5418-4e37-9b77-b4f3ca7f980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"John walks in the park\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec635d-f20c-491c-952c-8627329cd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = BobcatParser()\n",
    "diagram = parser.sentence2diagram(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443184b7-5fb4-4c00-91da-83cd2cb0398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar.draw(diagram, figsize=(16, 4), fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf117b3-7590-4d0d-bef5-106202c73bcc",
   "metadata": {},
   "source": [
    "### Diagram rewriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401443d6-6a3a-4813-9794-e052a359e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepositional phrase rewrite rule\n",
    "rewriter = Rewriter([\"prepositional_phrase\", \"determiner\"])\n",
    "rewritten_diagram = rewriter(diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c9c1dd-590b-4b57-90c0-e931fffcefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewritten_diagram.draw(figsize=(16, 4), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb365b04-bdc8-475d-bf39-420240aafca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "normalized_diagram = rewritten_diagram.normal_form()\n",
    "normalized_diagram.draw(figsize=(16, 4), fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d557f18-d778-4ae0-aaee-e9e797fcc015",
   "metadata": {},
   "source": [
    "### Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b74a8c-5161-4693-ab2b-063fba751471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atomic types\n",
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67172ac-2435-4a95-9067-ac2faa422d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string diagram to qc - 1 qubit per atomic type\n",
    "ansatz = IQPAnsatz({N: 1, S: 1}, n_layers=2)\n",
    "discopy_circuit = ansatz(normalized_diagram)\n",
    "discopy_circuit.draw(figsize=(40, 16), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b5d20-f009-4b05-ab14-40587a736e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert qc from DisCoPy to pytket format\n",
    "tket_circuit = discopy_circuit.to_tk()\n",
    "render_circuit_jupyter(tket_circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d4bd56-ba47-4f2e-a17b-234a4d7f72f0",
   "metadata": {},
   "source": [
    "### Training: Quantum case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4909c1-0056-4a35-ae9e-82eeb8f0f3ab",
   "metadata": {},
   "source": [
    "Inspecting `grammar.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e89bcc-f8e0-4e4b-bc4f-c80f203630b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f265f52-4bc3-4af5-a6a0-ae7698c4e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_json_path = \"/home/jovyan/.cache/lambeq/bobcat/bert/grammar.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f59f0c-c5fc-4b20-b016-ccc3bb129646",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(grammar_json_path, \"r\") as f:\n",
    "    grammar_json = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f91e34-7fed-42f9-91ca-afb2438d1156",
   "metadata": {},
   "source": [
    "Based on the sentence structures, we have the following grammatical structures. This might be important later.\n",
    "- Noun\n",
    "- Noun phrase\n",
    "- Sentence\n",
    "- Verb (transitive)\n",
    "- Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf3f9ea-b26a-40e4-a3b5-f1d1138a27d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = BobcatParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3dea6c-cb15-4fa4-80d4-1886313848f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f412f83-8c59-4b4f-9579-f0a04b4cf53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41610dd-14d3-4e65-b92d-a8dbac716330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"label\"] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cace6f-c9e4-492a-93dc-5f898fa47fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba728f-d3b0-4c50-b037-029e5d121d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val, df_test = train_test_split(df, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cdb169-3eb1-45b2-94af-0e61f25d429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f01e7-2853-4163-87a5-b0a7c401e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e500a5-0d44-48fa-babb-109d60d5299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3bacaa-da27-41b9-a526-b976e7a2dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rskf_splits = list(rskf.split(df_train_val[[\"s1\", \"s2\"]], y=df_train_val[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a097e-f7f0-4064-8572-c36ee01c67d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs, pn, d = (2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1f756-117f-46c6-980c-39df1e48bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = IQPAnsatz({AtomicType.NOUN: qs, AtomicType.SENTENCE: 1},\n",
    "                   n_single_qubit_params=pn, n_layers=d,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e3c16c-6e71-458a-a1ca-01a515bffad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rskf_splits[0][0].shape, rskf_splits[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1d386-830e-4e2b-aff3-3a54589d10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = rskf_splits[0]\n",
    "df_train, df_val = df_train_val.iloc[train_idx], df_train_val.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3151c1f1-d59f-4665-a0d0-2c498f376f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[df_train[\"label\"] == 0].shape)\n",
    "print(df_train[df_train[\"label\"] == 1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ee093-31de-4b7b-a6b5-5e080913aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df, ansatz):\n",
    "    # Create raw diagram for both datasets.\n",
    "    # We require both sentences to have a diagram\n",
    "    # so it can be part of the dataset.\n",
    "    df[\"s1_diagram\"] = parser.sentences2diagrams(list(df[\"s1\"].values), suppress_exceptions=True)\n",
    "    df[\"s2_diagram\"] = parser.sentences2diagrams(list(df[\"s2\"].values), suppress_exceptions=True)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Convert to normal form\n",
    "    df[\"s1_diagram\"] = df[\"s1_diagram\"].apply(lambda d: d.normal_form())\n",
    "    df[\"s2_diagram\"] = df[\"s2_diagram\"].apply(lambda d: d.normal_form())\n",
    "\n",
    "    # Vectorize label\n",
    "    df[\"label_v\"] = df[\"label\"].apply(lambda l: [0, 1] if l == 0 else [1, 0])\n",
    "\n",
    "    # Create circuits\n",
    "    df[\"s1_circuit\"] = df[\"s1_diagram\"].apply(lambda d: ansatz(remove_cups(d)))\n",
    "    df[\"s2_circuit\"] = df[\"s2_diagram\"].apply(lambda d: ansatz(remove_cups(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c240f299-0076-4b6f-a7a1-25760c57814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_df(df_train, ansatz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e2054-1bce-4820-a148-88775247a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8eee66-c164-402e-b6d2-0f6fd082154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"s1_diagram\"][40].draw(figsize=(4, 3), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ebed54-c51c-490d-9562-6d43a6937954",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"s2_diagram\"][40].draw(figsize=(4, 3), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255717cc-2da7-4141-abc4-2c0e5aaafacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"s1_circuit\"][40].draw(figsize=(4, 3), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28aa2e5-d9a0-4d3e-a075-ff7217f5578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"s2_circuit\"][40].draw(figsize=(4, 3), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e63e01-afe5-4979-b01f-f1b3087f26ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_circuit_jupyter(df_train[\"s1_circuit\"][40].to_tk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5363ff-0e83-4b6c-bdff-ce4cd8d98dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_circuit_jupyter(df_train[\"s2_circuit\"][40].to_tk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1e6f14-0a24-4745-830e-c5dce4efbfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_df(df_val, ansatz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73a0ade-f71e-44a8-9e02-c2679bb17ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_df(df_test, ansatz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9332b8c1-2850-40f5-a985-45985cba32ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_circuits = list(df_train[[\"s1_circuit\", \"s2_circuit\"]].values)\n",
    "val_circuits = list(df_val[[\"s1_circuit\", \"s2_circuit\"]].values)\n",
    "test_circuits = list(df_test[[\"s1_circuit\", \"s2_circuit\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9656e3-ec37-4f68-85e9-2ca9277f939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_circuits = train_circuits + val_circuits + test_circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb1646-b578-42d1-b67a-af651fd8caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(all_circuits) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e2d7d-3018-49b4-9731-029ca9e4cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diagrams = list(df_train[[\"s1_diagram\", \"s2_diagram\"]].values)\n",
    "val_diagrams = list(df_val[[\"s1_diagram\", \"s2_diagram\"]].values)\n",
    "test_diagrams = list(df_test[[\"s1_diagram\", \"s2_diagram\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee705d6-9164-4a79-8c4f-89237d241693",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diagrams = train_diagrams + val_diagrams + test_diagrams             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac98b6-962d-49b4-9563-5ea66e84413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = list(df_train[\"label_v\"].values)\n",
    "val_labels = list(df_val[\"label_v\"].values)\n",
    "test_labels = list(df_test[\"label_v\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21649ff-54ed-4b26-8db3-26d740bebb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = AerBackend()\n",
    "backend_config = {\n",
    "    \"backend\": backend,\n",
    "    \"compilation\": backend.default_compilation_pass(2),\n",
    "    \"shots\": 2**13,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6187f29-1c32-4d24-a357-3ba8e616f0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomTketModel(TketModel):\n",
    "    def forward(self, x: list[[Diagram, Diagram]]) -> np.ndarray:\n",
    "        # The forward pass takes x with 2 circuits\n",
    "        # for each of the sentence being compared\n",
    "        s1_diagrams = []\n",
    "        s2_diagrams = []\n",
    "        n_rows = len(x)\n",
    "        for s1d, s2d in x:\n",
    "            s1_diagrams.append(s1d)\n",
    "            s2_diagrams.append(s2d)\n",
    "        \n",
    "        s1_output = self.get_diagram_output(s1_diagrams)\n",
    "        s2_output = self.get_diagram_output(s2_diagrams)\n",
    "        s1_output = s1_output.reshape((n_rows, -1))[:,:2]\n",
    "        s2_output = s2_output.reshape((n_rows, -1))[:,:2]\n",
    "        \n",
    "        s1_output_norm = np.sqrt(np.sum(s1_output * s1_output, axis=1))\n",
    "        s2_output_norm = np.sqrt(np.sum(s2_output * s2_output, axis=1))\n",
    "        denom = s1_output_norm * s2_output_norm\n",
    "        s1_dot_s2 = np.sum(s1_output[:,:2] * s2_output[:,:2], axis=1) / denom\n",
    "\n",
    "        complement = np.ones_like(s1_dot_s2) - s1_dot_s2\n",
    "        out = np.array([s1_dot_s2,\n",
    "                        complement]).T\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df724861-9099-4598-b9d5-076a6dbc57d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNumpyModel(NumpyModel):\n",
    "    def forward(self, x: list[[Diagram, Diagram]]) -> np.ndarray:\n",
    "        # The forward pass takes x with 2 circuits\n",
    "        # for each of the sentence being compared\n",
    "        s1_diagrams = []\n",
    "        s2_diagrams = []\n",
    "        n_rows = len(x)\n",
    "        for s1d, s2d in x:\n",
    "            s1_diagrams.append(s1d)\n",
    "            s2_diagrams.append(s2d)\n",
    "        \n",
    "        s1_output = self.get_diagram_output(s1_diagrams)\n",
    "        s2_output = self.get_diagram_output(s2_diagrams)\n",
    "        s1_output = s1_output.reshape((n_rows, -1))[:,:2]\n",
    "        s2_output = s2_output.reshape((n_rows, -1))[:,:2]\n",
    "        \n",
    "        s1_output_norm = np.sqrt(np.sum(s1_output * s1_output, axis=1))\n",
    "        s2_output_norm = np.sqrt(np.sum(s2_output * s2_output, axis=1))\n",
    "        denom = s1_output_norm * s2_output_norm\n",
    "        s1_dot_s2 = np.sum(s1_output[:,:2] * s2_output[:,:2], axis=1) / denom\n",
    "\n",
    "        complement = np.ones_like(s1_dot_s2) - s1_dot_s2\n",
    "        out = np.array([s1_dot_s2,\n",
    "                        complement]).T\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ecb9f-d26c-45a2-9edf-c7d631aefabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_circuits).reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c9d0cc-a3f2-40c9-ac93-4a2007025034",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df5798c-38d3-49cf-b693-4aee891278da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_circuits,\n",
    "                        train_labels,\n",
    "                        batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692e226-eb84-48a6-84fd-e86b81d59875",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset(val_circuits,\n",
    "                      val_labels,\n",
    "                      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba400f65-377a-43f2-b009-9ae8c9e5daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lambda y_hat, y: -np.sum(y * np.log(y_hat)) / len(y)\n",
    "acc = lambda y_hat, y: np.sum(np.round(y_hat) == y) / len(y) / 2\n",
    "eval_metrics = {\"acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ebc2d-798f-4746-aa05-17d717a0bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tket_model = CustomTketModel.from_diagrams(np.array(all_circuits).reshape(-1),\n",
    "                                           backend_config=backend_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d5759d-fc8f-49ee-8c51-5c69e5d6b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_model = CustomNumpyModel.from_diagrams(np.array(all_circuits).reshape(-1),\n",
    "                                           use_jit=True)\n",
    "                                           #backend_config=backend_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da28d029-3742-4150-b2cc-6660c89f722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = QuantumTrainer(\n",
    "    tket_model,\n",
    "    loss_function=loss,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={\"a\": 0.05, \"c\": 0.06, \"A\": 0.01 * EPOCHS},\n",
    "    evaluate_functions=eval_metrics,\n",
    "    verbose=\"text\",\n",
    "    seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f550b-61dd-486f-94ab-d33c7d0b2edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3365ea-549e-473d-b332-28a23dbb679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (qs, pn, d) = (2, 3, 1)\n",
    "trainer.fit(train_dataset, val_dataset, evaluation_step=1, logging_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461380bd-21f9-46b9-b8e3-c97c494c5391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (qs, pn, d) = (2, 3, 1)\n",
    "trainer.fit(train_dataset, val_dataset, evaluation_step=1, logging_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb2185-2dce-41d7-b12f-eeece1c44944",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2,\n",
    "                                                     sharex=True,\n",
    "                                                     sharey=\"row\",\n",
    "                                                     figsize=(12, 6))\n",
    "\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(trainer.train_epoch_costs[::2], color=next(colours))\n",
    "ax_bl.plot(trainer.train_results['acc'][::2], color=next(colours))\n",
    "ax_tr.plot(trainer.val_costs[::2], color=next(colours))\n",
    "ax_br.plot(trainer.val_results['acc'][::2], color=next(colours))\n",
    "\n",
    "# print test accuracy\n",
    "test_acc = acc(tket_model(val_circuits), val_labels)\n",
    "print('Validation accuracy:', test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d367cb-05d7-4d84-be7b-bf49af0f065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (qs, pn, d) = (1, 3, 2)\n",
    "trainer.fit(train_dataset, val_dataset, evaluation_step=1, logging_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e3789f-818b-447f-9613-c30a48a09619",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2,\n",
    "                                                     sharex=True,\n",
    "                                                     sharey=\"row\",\n",
    "                                                     figsize=(12, 6))\n",
    "\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(trainer.train_epoch_costs, color=next(colours))\n",
    "ax_bl.plot(trainer.train_results['acc'], color=next(colours))\n",
    "ax_tr.plot(trainer.val_costs, color=next(colours))\n",
    "ax_br.plot(trainer.val_results['acc'], color=next(colours))\n",
    "\n",
    "# print test accuracy\n",
    "test_acc = acc(tket_model(val_circuits), val_labels)\n",
    "print('Validation accuracy:', test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364e902-2735-4f41-acd2-a00cdbd91e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (qs, pn, d) = (1, 3, 1)\n",
    "trainer.fit(train_dataset, val_dataset, evaluation_step=1, logging_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a2b9bf-2817-4035-a23d-3df236d380f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2,\n",
    "                                                     sharex=True,\n",
    "                                                     sharey=\"row\",\n",
    "                                                     figsize=(12, 6))\n",
    "\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(trainer.train_epoch_costs, color=next(colours))\n",
    "ax_bl.plot(trainer.train_results['acc'], color=next(colours))\n",
    "ax_tr.plot(trainer.val_costs, color=next(colours))\n",
    "ax_br.plot(trainer.val_results['acc'], color=next(colours))\n",
    "\n",
    "# print test accuracy\n",
    "test_acc = acc(tket_model(val_circuits), val_labels)\n",
    "print('Validation accuracy:', test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa02e2-e3a3-4bcc-9902-9dd938036aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (qs, pn, d) = (1, 1, 2)\n",
    "trainer.fit(train_dataset, val_dataset, evaluation_step=1, logging_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da7161-9e6f-4c90-a2f4-b9d2e7bbec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2,\n",
    "                                                     sharex=True,\n",
    "                                                     sharey=\"row\",\n",
    "                                                     figsize=(12, 6))\n",
    "\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(trainer.train_epoch_costs, color=next(colours))\n",
    "ax_bl.plot(trainer.train_results['acc'], color=next(colours))\n",
    "ax_tr.plot(trainer.val_costs, color=next(colours))\n",
    "ax_br.plot(trainer.val_results['acc'], color=next(colours))\n",
    "\n",
    "# print test accuracy\n",
    "test_acc = acc(tket_model(val_circuits), val_labels)\n",
    "print('Validation accuracy:', test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd7e825-b00d-48a5-977a-c79141be2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (qs, pn, d) = (1, 1, 1)\n",
    "trainer.fit(train_dataset, val_dataset, evaluation_step=1, logging_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b70fc-31cd-41c7-882a-0bc8c0ad250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae84a1-eda7-43f3-b4c8-1c4122e6b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use([\"ipynb\", \"use_tex\", \"colors10-ls\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f0027a-8300-447e-a397-9dbc889b53bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2,\n",
    "                                                     sharex=True,\n",
    "                                                     sharey=\"row\",\n",
    "                                                     figsize=(12, 6))\n",
    "\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(trainer.train_epoch_costs, color=next(colours))\n",
    "ax_bl.plot(trainer.train_results['acc'], color=next(colours))\n",
    "ax_tr.plot(trainer.val_costs, color=next(colours))\n",
    "ax_br.plot(trainer.val_results['acc'], color=next(colours))\n",
    "\n",
    "# print test accuracy\n",
    "test_acc = acc(tket_model(val_circuits), val_labels)\n",
    "print('Validation accuracy:', test_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961abd60-0add-4b8b-bc83-7a25a3078882",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = trainer.log_dir\n",
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c72bf-d938-4e4b-b0f2-ba57d9c31ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tket_model.make_checkpoint(\"./checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e409e8e-14f7-4edd-aec1-5344c4615507",
   "metadata": {},
   "source": [
    "### Aside: What happens during the forward pass?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109ef5b-baeb-43ac-b714-a121cd3b0c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from discopy.quantum import Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc525c0c-050b-4b47-b5b9-686a5c87fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_circuits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c14699-2164-4c4f-a1d2-a3ba7a8d9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diagrams[0].draw(figsize=(16, 9), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e4266-57db-4c98-8526-a3c2e3b006e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_circuits[0].draw(figsize=(16, 9), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebffb5f8-b3bf-4542-a979-5d64e7d1c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_circuit_jupyter(all_circuits[0].to_tk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dde5b1-1397-4a59-b115-0bce56d10d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdified_diagram = model._make_lambda(all_circuits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04eb1eb-c76b-43ad-a8cf-8b18f5081caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lambdified_diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f0612f-a7cf-45dd-b86f-d465ad2a45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264fb6b-1544-4849-8c6a-55bb5a4591e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = Circuit.eval(\n",
    "    *lambdified_diagram(*model.weights),\n",
    "    **model.backend_config,\n",
    "    seed=model._randint(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aec440-b4b8-4234-8218-7ba2a50de193",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdified_diagram(*model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a79d5b-912a-4c0d-ac69-997fe0446c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f141f-bfb6-49fe-b2a3-c5457e295c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([model._normalise_vector(t.array) for t in tensors])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec532af-98a5-482c-9402-104b83f00a03",
   "metadata": {},
   "source": [
    "## Questions/Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4561234c-28a4-4725-8120-4691ece5ddb2",
   "metadata": {},
   "source": [
    "- What is getting measured?\n",
    "- Domain = input, codomain = output, box = function\n",
    "- Model must receive __ALL__ circuits during init - including all datasplits. This is similar to sequence models having a fixed sequence length during init."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e24a05c-9c3e-4deb-948a-3fb4d060e29c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd063f-430a-4a3a-81f8-e5a1676e48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomNumpyModel.from_diagrams(np.array(all_circuits).reshape(-1),\n",
    "                                       use_jit=True,)\n",
    "                                       # backend_config=backend_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3446f-81bc-4c0b-a5b7-3978b9171aab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Customize QuantumTrainer\n",
    "from abc import ABC, abstractmethod\n",
    "from collections.abc import Callable, Mapping\n",
    "from datetime import datetime\n",
    "from math import ceil\n",
    "import os\n",
    "import random\n",
    "import socket\n",
    "import sys\n",
    "from typing import Any, Optional, Union\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "from discopy import Tensor\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from lambeq.core.globals import VerbosityLevel\n",
    "from lambeq.training.checkpoint import Checkpoint\n",
    "from lambeq.training.dataset import Dataset\n",
    "from lambeq.training.model import Model\n",
    "\n",
    "\n",
    "def _import_tensorboard_writer() -> None:\n",
    "    global SummaryWriter\n",
    "    try:\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "    except ImportError:  # pragma: no cover\n",
    "        raise ImportError('tensorboard not found. Please install it using '\n",
    "                          '`pip install tensorboard`.')\n",
    "\n",
    "\n",
    "_StrPathT = Union[str, 'os.PathLike[str]']\n",
    "\n",
    "\n",
    "class CustomQuantumTrainer(QuantumTrainer):\n",
    "    def fit(self,\n",
    "            train_dataset: Dataset,\n",
    "            val_dataset: Optional[Dataset] = None,\n",
    "            evaluation_step: int = 1,\n",
    "            logging_step: int = 1) -> None:\n",
    "        \"\"\"Fit the model on the training data and, optionally,\n",
    "        evaluate it on the validation data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_dataset : :py:class:`Dataset`\n",
    "            Dataset used for training.\n",
    "        val_dataset : :py:class:`Dataset`, optional\n",
    "            Validation dataset.\n",
    "        evaluation_step : int, default: 1\n",
    "            Sets the intervals at which the metrics are evaluated on the\n",
    "            validation dataset.\n",
    "        logging_step : int, default: 1\n",
    "            Sets the intervals at which the training statistics are\n",
    "            printed if `verbose = 'text'` (otherwise ignored).\n",
    "\n",
    "        \"\"\"\n",
    "        if self.from_checkpoint:\n",
    "            self._load_extra_chkpoint_info(self.checkpoint)\n",
    "\n",
    "        def writer_helper(*args: Any) -> None:\n",
    "            if self.use_tensorboard:\n",
    "                self.writer.add_scalar(*args)\n",
    "            else:\n",
    "                print(*args)\n",
    "\n",
    "        # initialise progress bar\n",
    "        step = self.start_step\n",
    "        batches_per_epoch = ceil(len(train_dataset)/train_dataset.batch_size)\n",
    "        status_bar = tqdm(total=float('inf'),\n",
    "                          bar_format='{desc}',\n",
    "                          desc=self._generate_stat_report(),\n",
    "                          disable=(\n",
    "                                self.verbose != VerbosityLevel.PROGRESS.value),\n",
    "                          leave=True,\n",
    "                          position=0)\n",
    "\n",
    "        # start training loop\n",
    "        for epoch in trange(self.start_epoch,\n",
    "                            self.epochs,\n",
    "                            desc='Epoch',\n",
    "                            disable=(\n",
    "                                self.verbose != VerbosityLevel.PROGRESS.value),\n",
    "                            leave=False,\n",
    "                            position=1):\n",
    "            train_loss = 0.0\n",
    "            with Tensor.backend(self.backend):\n",
    "                for batch in tqdm(train_dataset,\n",
    "                                  desc='Batch',\n",
    "                                  total=batches_per_epoch,\n",
    "                                  disable=(self.verbose\n",
    "                                           != VerbosityLevel.PROGRESS.value),\n",
    "                                  leave=False,\n",
    "                                  position=2):\n",
    "                    step += 1\n",
    "                    x, y_label = batch\n",
    "                    y_hat, loss = self.training_step(batch)\n",
    "                    if (self.evaluate_on_train\n",
    "                            and self.evaluate_functions is not None):\n",
    "                        for metr, func in self.evaluate_functions.items():\n",
    "                            res = func(y_hat, y_label)\n",
    "                            metric = self._train_results_epoch[metr]\n",
    "                            metric.append(len(x) * res)\n",
    "                    train_loss += len(batch[0]) * loss\n",
    "                    writer_helper('train/step_loss', loss, step)\n",
    "                    status_bar.set_description(\n",
    "                            self._generate_stat_report(\n",
    "                                train_loss=loss,\n",
    "                                val_loss=(self.val_costs[-1] if self.val_costs\n",
    "                                          else None)))\n",
    "            train_loss /= len(train_dataset)\n",
    "            self.train_epoch_costs.append(train_loss)\n",
    "            writer_helper('train/epoch_loss', train_loss, epoch + 1)\n",
    "\n",
    "            # evaluate on train\n",
    "            if (self.evaluate_on_train\n",
    "                    and self.evaluate_functions is not None):\n",
    "                for name in self._train_results_epoch:\n",
    "                    self.train_results[name].append(\n",
    "                        sum(self._train_results_epoch[name])/len(train_dataset)\n",
    "                    )\n",
    "                    self._train_results_epoch[name] = []  # reset\n",
    "                    writer_helper(\n",
    "                        f'train/{name}', self.train_results[name][-1],\n",
    "                        epoch+1)\n",
    "                    if self.verbose == VerbosityLevel.PROGRESS.value:\n",
    "                        status_bar.set_description(\n",
    "                                self._generate_stat_report(\n",
    "                                    train_loss=train_loss,\n",
    "                                    val_loss=(self.val_costs[-1]\n",
    "                                              if self.val_costs else None)))\n",
    "\n",
    "            # evaluate metrics on validation data\n",
    "            if val_dataset is not None:\n",
    "                if epoch % evaluation_step == 0:\n",
    "                    val_loss = 0.0\n",
    "                    batches_per_validation = ceil(len(val_dataset)\n",
    "                                                  / val_dataset.batch_size)\n",
    "                    writer_helper('batches_per_validation', batches_per_validation, len(val_dataset), val_dataset.batch_size)\n",
    "                    with Tensor.backend(self.backend):\n",
    "                        disable_tqdm = (self.verbose\n",
    "                                        != VerbosityLevel.PROGRESS.value)\n",
    "                        for v_batch in tqdm(val_dataset,\n",
    "                                            desc='Validation batch',\n",
    "                                            total=batches_per_validation,\n",
    "                                            disable=disable_tqdm,\n",
    "                                            leave=False,\n",
    "                                            position=2):\n",
    "                            writer_helper(\"***\", v_batch)\n",
    "                            x_val, y_label_val = v_batch\n",
    "                            writer_helper(\"***\", x_val, y_label_val)\n",
    "                            y_hat_val, cur_loss = self.validation_step(v_batch)\n",
    "                            writer_helper(\"***\", y_hat_val, cur_loss)\n",
    "                            val_loss += cur_loss * len(x_val)\n",
    "                            if self.evaluate_functions is not None:\n",
    "                                for metr, func in (\n",
    "                                        self.evaluate_functions.items()):\n",
    "                                    res = func(y_hat_val, y_label_val)\n",
    "                                    self._val_results_epoch[metr].append(\n",
    "                                        len(x_val)*res)\n",
    "                            status_bar.set_description(\n",
    "                                    self._generate_stat_report(\n",
    "                                        train_loss=train_loss,\n",
    "                                        val_loss=val_loss))\n",
    "                        val_loss /= len(val_dataset)\n",
    "                        self.val_costs.append(val_loss)\n",
    "                        status_bar.set_description(\n",
    "                                self._generate_stat_report(\n",
    "                                    train_loss=train_loss,\n",
    "                                    val_loss=val_loss))\n",
    "                        writer_helper('val/loss', val_loss, epoch+1)\n",
    "\n",
    "                    if self.evaluate_functions is not None:\n",
    "                        for name in self._val_results_epoch:\n",
    "                            self.val_results[name].append(\n",
    "                                sum(self._val_results_epoch[name])\n",
    "                                / len(val_dataset))\n",
    "                            self._val_results_epoch[name] = []  # reset\n",
    "                            writer_helper(\n",
    "                                f'val/{name}', self.val_results[name][-1],\n",
    "                                epoch + 1)\n",
    "                            status_bar.set_description(\n",
    "                                    self._generate_stat_report(\n",
    "                                        train_loss=train_loss,\n",
    "                                        val_loss=val_loss))\n",
    "            # save checkpoint info\n",
    "            save_dict = {'epoch': epoch+1,\n",
    "                         'model_weights': self.model.weights,\n",
    "                         'model_symbols': self.model.symbols,\n",
    "                        'train_costs': self.train_costs,\n",
    "                         'train_epoch_costs': self.train_epoch_costs,\n",
    "                         'train_results': self.train_results,\n",
    "                         'val_costs': self.val_costs,\n",
    "                         'val_results': self.val_results,\n",
    "                         'random_state': random.getstate(),\n",
    "                         'step': step}\n",
    "            print(f\"save_dict: {save_dict}\")\n",
    "            self.save_checkpoint(save_dict, self.log_dir)\n",
    "            if self.verbose == VerbosityLevel.TEXT.value:\n",
    "                if epoch == 0 or (epoch+1) % logging_step == 0:\n",
    "                    space = (len(str(self.epochs))-len(str(epoch+1)) + 2) * ' '\n",
    "                    prefix = f'Epoch {epoch+1}:' + space\n",
    "                    print(prefix + self._generate_stat_report(\n",
    "                            train_loss=train_loss,\n",
    "                            val_loss=(self.val_costs[-1] if self.val_costs\n",
    "                                      else None)),\n",
    "                          file=sys.stderr)\n",
    "        status_bar.close()\n",
    "        if self.verbose == VerbosityLevel.TEXT.value:\n",
    "            print('\\nTraining completed!', file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59ed4b-1cec-4cf1-a135-0d86b5fe9a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
